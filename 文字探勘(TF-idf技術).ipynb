{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "showing info https://raw.githubusercontent.com/nltk/nltk_data/gh-pages/index.xml\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The first time I heard that song was in Hawaii on radio....',\n",
       " 'I was just a kid, and loved it very much!',\n",
       " 'What a fantastic song!']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent_tokenizer = nltk.data.load('tokenizers/punkt/english.pickle')#此套件可先將文章做分句的動作\n",
    "paragraph = \"The first time I heard that song was in Hawaii on radio.... I was just a kid, and loved it very much! What a fantastic song!\"\n",
    "sentences = sent_tokenizer.tokenize(paragraph)\n",
    "sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The',\n",
       " 'first',\n",
       " 'time',\n",
       " 'I',\n",
       " 'heard',\n",
       " 'that',\n",
       " 'song',\n",
       " 'was',\n",
       " 'in',\n",
       " 'Hawaii',\n",
       " 'on',\n",
       " 'radio',\n",
       " '....',\n",
       " 'I',\n",
       " 'was',\n",
       " 'just',\n",
       " 'a',\n",
       " 'kid',\n",
       " ',',\n",
       " 'and',\n",
       " 'loved',\n",
       " 'it',\n",
       " 'very',\n",
       " 'much',\n",
       " '!',\n",
       " 'What',\n",
       " 'a',\n",
       " 'fantastic',\n",
       " 'song',\n",
       " '!']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.tokenize import WordPunctTokenizer \n",
    "words = WordPunctTokenizer().tokenize(paragraph)\n",
    "words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import math\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "from collections import Counter\n",
    "from nltk.stem.porter import *\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "text1 = \"Python is a 2000 made-for-TV horror movie directed by Richard \\\n",
    "Clabaugh. The film features several cult favorite actors, including William \\\n",
    "Zabka of The Karate Kid fame, Wil Wheaton, Casper Van Dien, Jenny McCarthy, \\\n",
    "Keith Coogan, Robert Englund (best known for his role as Freddy Krueger in the \\\n",
    "A Nightmare on Elm Street series of films), Dana Barron, David Bowe, and Sean \\\n",
    "Whalen. The film concerns a genetically engineered snake, a python, that \\\n",
    "escapes and unleashes itself on a small town. It includes the classic final\\\n",
    "girl scenario evident in films like Friday the 13th. It was filmed in Los Angeles, \\\n",
    "California and Malibu, California. Python was followed by two sequels: Python \\\n",
    "II (2002) and Boa vs. Python (2004), both also made-for-TV films.\"\n",
    "text2 = \"Python, from the Greek word (πύθων/πύθωνας), is a genus of \\\n",
    "nonvenomous pythons[2] found in Africa and Asia. Currently, 7 species are \\\n",
    "recognised.[2] A member of this genus, P. reticulatus, is among the longest \\\n",
    "snakes known.\"\n",
    "text3 = \"The Colt Python is a .357 Magnum caliber revolver formerly \\\n",
    "manufactured by Colt's Manufacturing Company of Hartford, Connecticut. \\\n",
    "It is sometimes referred to as a \\\"Combat Magnum\\\".[1] It was first introduced \\\n",
    "in 1955, the same year as Smith & Wesson's M29 .44 Magnum. The now discontinued \\\n",
    "Colt Python targeted the premium revolver market segment. Some firearm \\\n",
    "collectors and writers such as Jeff Cooper, Ian V. Hogg, Chuck Hawks, Leroy \\\n",
    "Thompson, Renee Smeets and Martin Dougherty have described the Python as the \\\n",
    "finest production revolver ever made.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Python is a 2000 made for TV horror movie directed by Richard Clabaugh  The film features several cult favorite actors  including William Zabka of The Karate Kid fame  Wil Wheaton  Casper Van Dien  Jenny McCarthy  Keith Coogan  Robert Englund  best known for his role as Freddy Krueger in the A Nightmare on Elm Street series of films   Dana Barron  David Bowe  and Sean Whalen  The film concerns a genetically engineered snake  a python  that escapes and unleashes itself on a small town  It includes the classic finalgirl scenario evident in films like Friday the 13th  It was filmed in Los Angeles  California and Malibu  California  Python was followed by two sequels  Python II  2002  and Boa vs  Python  2004   both also made for TV films '"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#刪除文章標點符號方式\n",
    "text1 = \"Python is a 2000 made-for-TV horror movie directed by Richard \\\n",
    "Clabaugh. The film features several cult favorite actors, including William \\\n",
    "Zabka of The Karate Kid fame, Wil Wheaton, Casper Van Dien, Jenny McCarthy, \\\n",
    "Keith Coogan, Robert Englund (best known for his role as Freddy Krueger in the \\\n",
    "A Nightmare on Elm Street series of films), Dana Barron, David Bowe, and Sean \\\n",
    "Whalen. The film concerns a genetically engineered snake, a python, that \\\n",
    "escapes and unleashes itself on a small town. It includes the classic final\\\n",
    "girl scenario evident in films like Friday the 13th. It was filmed in Los Angeles, \\\n",
    "California and Malibu, California. Python was followed by two sequels: Python \\\n",
    "II (2002) and Boa vs. Python (2004), both also made-for-TV films.\"\n",
    "\n",
    "for x in text1:\n",
    "    if x in string.punctuation:\n",
    "        text1=text1.replace(x,\" \")\n",
    "        \n",
    "text1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "text1 = \"Python is a 2000 made-for-TV horror movie directed by Richard \\\n",
    "Clabaugh. The film features several cult favorite actors, including William \\\n",
    "Zabka of The Karate Kid fame, Wil Wheaton, Casper Van Dien, Jenny McCarthy, \\\n",
    "Keith Coogan, Robert Englund (best known for his role as Freddy Krueger in the \\\n",
    "A Nightmare on Elm Street series of films), Dana Barron, David Bowe, and Sean \\\n",
    "Whalen. The film concerns a genetically engineered snake, a python, that \\\n",
    "escapes and unleashes itself on a small town. It includes the classic final\\\n",
    "girl scenario evident in films like Friday the 13th. It was filmed in Los Angeles, \\\n",
    "California and Malibu, California. Python was followed by two sequels: Python \\\n",
    "II (2002) and Boa vs. Python (2004), both also made-for-TV films.\"\n",
    "\n",
    "\n",
    "def get_tokens(test):\n",
    "    lowers = test.lower()#轉化成小寫\n",
    "    remove_punctuation_map = dict((ord(x),None) for x in string.punctuation) #ord()將特定字符(ascii)轉為數字(unicode)\n",
    "    no_punctuation = lowers.translate(remove_punctuation_map) #此行進行轉換的動作(目標.translate(轉換規則))\n",
    "    tokens = nltk.word_tokenize(no_punctuation) #分句\n",
    "    return tokens#輸出結果(tokens)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['python', 'is', 'a', '2000', 'madefortv', 'horror', 'movie', 'directed', 'by', 'richard', 'clabaugh', 'the', 'film', 'features', 'several', 'cult', 'favorite', 'actors', 'including', 'william', 'zabka', 'of', 'the', 'karate', 'kid', 'fame', 'wil', 'wheaton', 'casper', 'van', 'dien', 'jenny', 'mccarthy', 'keith', 'coogan', 'robert', 'englund', 'best', 'known', 'for', 'his', 'role', 'as', 'freddy', 'krueger', 'in', 'the', 'a', 'nightmare', 'on', 'elm', 'street', 'series', 'of', 'films', 'dana', 'barron', 'david', 'bowe', 'and', 'sean', 'whalen', 'the', 'film', 'concerns', 'a', 'genetically', 'engineered', 'snake', 'a', 'python', 'that', 'escapes', 'and', 'unleashes', 'itself', 'on', 'a', 'small', 'town', 'it', 'includes', 'the', 'classic', 'finalgirl', 'scenario', 'evident', 'in', 'films', 'like', 'friday', 'the', '13th', 'it', 'was', 'filmed', 'in', 'los', 'angeles', 'california', 'and', 'malibu', 'california', 'python', 'was', 'followed', 'by', 'two', 'sequels', 'python', 'ii', '2002', 'and', 'boa', 'vs', 'python', '2004', 'both', 'also', 'madefortv', 'films']\n"
     ]
    }
   ],
   "source": [
    "print(get_tokens(text1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('the', 6), ('python', 5), ('a', 5), ('and', 4), ('in', 3), ('films', 3), ('madefortv', 2), ('by', 2), ('film', 2), ('of', 2)]\n"
     ]
    }
   ],
   "source": [
    "tokens = get_tokens(text1)\n",
    "count = Counter(tokens)\n",
    "print (count.most_common(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('python', 5), ('films', 3), ('madefortv', 2), ('film', 2), ('california', 2), ('2000', 1), ('horror', 1), ('movie', 1), ('directed', 1), ('richard', 1)]\n"
     ]
    }
   ],
   "source": [
    "tokens = get_tokens(text1)\n",
    "filtered = [w for w in tokens if not w in stopwords.words('english')]  #stopwords 刪除非必要詞語 EX:a , he , i ....\n",
    "count1 = Counter(filtered)\n",
    "print(count1.most_common(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'python': 5, 'films': 3, 'madefortv': 2, 'film': 2, 'california': 2, '2000': 1, 'horror': 1, 'movie': 1, 'directed': 1, 'richard': 1, 'clabaugh': 1, 'features': 1, 'several': 1, 'cult': 1, 'favorite': 1, 'actors': 1, 'including': 1, 'william': 1, 'zabka': 1, 'karate': 1, 'kid': 1, 'fame': 1, 'wil': 1, 'wheaton': 1, 'casper': 1, 'van': 1, 'dien': 1, 'jenny': 1, 'mccarthy': 1, 'keith': 1, 'coogan': 1, 'robert': 1, 'englund': 1, 'best': 1, 'known': 1, 'role': 1, 'freddy': 1, 'krueger': 1, 'nightmare': 1, 'elm': 1, 'street': 1, 'series': 1, 'dana': 1, 'barron': 1, 'david': 1, 'bowe': 1, 'sean': 1, 'whalen': 1, 'concerns': 1, 'genetically': 1, 'engineered': 1, 'snake': 1, 'escapes': 1, 'unleashes': 1, 'small': 1, 'town': 1, 'includes': 1, 'classic': 1, 'finalgirl': 1, 'scenario': 1, 'evident': 1, 'like': 1, 'friday': 1, '13th': 1, 'filmed': 1, 'los': 1, 'angeles': 1, 'malibu': 1, 'followed': 1, 'two': 1, 'sequels': 1, 'ii': 1, '2002': 1, 'boa': 1, 'vs': 1, '2004': 1, 'also': 1})\n"
     ]
    }
   ],
   "source": [
    "print(count1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stem_tokens(target, stemmer):  #此函式是用來將類似詞彙編為同一類，例如:films,film其實是同一個東西，只是單複數的不相同，因此可用此函式將他們歸為同一類\n",
    "    stemmed = []\n",
    "    for item in target:\n",
    "        stemmed.append(stemmer.stem(item))\n",
    "    return stemmed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('film', 6), ('python', 5), ('madefortv', 2), ('includ', 2), ('california', 2), ('2000', 1), ('horror', 1), ('movi', 1), ('direct', 1), ('richard', 1)]\n"
     ]
    }
   ],
   "source": [
    "stemmer = PorterStemmer()\n",
    "stemmed = stem_tokens(filtered, stemmer)\n",
    "count2 = Counter(stemmed)\n",
    "print(count2.most_common(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_term(text):   #上述自然語言預處理的所有步驟的整合\n",
    "    tokens = get_tokens(text)\n",
    "    filtered = [w for w in tokens if not w in stopwords.words('english')]\n",
    "    stemmer = PorterStemmer()\n",
    "    stemmed = stem_tokens(filtered, stemmer)\n",
    "    count = Counter(stemmed)\n",
    "    return count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Counter({'python': 5,\n",
       "          '2000': 1,\n",
       "          'madefortv': 2,\n",
       "          'horror': 1,\n",
       "          'movi': 1,\n",
       "          'direct': 1,\n",
       "          'richard': 1,\n",
       "          'clabaugh': 1,\n",
       "          'film': 6,\n",
       "          'featur': 1,\n",
       "          'sever': 1,\n",
       "          'cult': 1,\n",
       "          'favorit': 1,\n",
       "          'actor': 1,\n",
       "          'includ': 2,\n",
       "          'william': 1,\n",
       "          'zabka': 1,\n",
       "          'karat': 1,\n",
       "          'kid': 1,\n",
       "          'fame': 1,\n",
       "          'wil': 1,\n",
       "          'wheaton': 1,\n",
       "          'casper': 1,\n",
       "          'van': 1,\n",
       "          'dien': 1,\n",
       "          'jenni': 1,\n",
       "          'mccarthi': 1,\n",
       "          'keith': 1,\n",
       "          'coogan': 1,\n",
       "          'robert': 1,\n",
       "          'englund': 1,\n",
       "          'best': 1,\n",
       "          'known': 1,\n",
       "          'role': 1,\n",
       "          'freddi': 1,\n",
       "          'krueger': 1,\n",
       "          'nightmar': 1,\n",
       "          'elm': 1,\n",
       "          'street': 1,\n",
       "          'seri': 1,\n",
       "          'dana': 1,\n",
       "          'barron': 1,\n",
       "          'david': 1,\n",
       "          'bow': 1,\n",
       "          'sean': 1,\n",
       "          'whalen': 1,\n",
       "          'concern': 1,\n",
       "          'genet': 1,\n",
       "          'engin': 1,\n",
       "          'snake': 1,\n",
       "          'escap': 1,\n",
       "          'unleash': 1,\n",
       "          'small': 1,\n",
       "          'town': 1,\n",
       "          'classic': 1,\n",
       "          'finalgirl': 1,\n",
       "          'scenario': 1,\n",
       "          'evid': 1,\n",
       "          'like': 1,\n",
       "          'friday': 1,\n",
       "          '13th': 1,\n",
       "          'lo': 1,\n",
       "          'angel': 1,\n",
       "          'california': 2,\n",
       "          'malibu': 1,\n",
       "          'follow': 1,\n",
       "          'two': 1,\n",
       "          'sequel': 1,\n",
       "          'ii': 1,\n",
       "          '2002': 1,\n",
       "          'boa': 1,\n",
       "          'vs': 1,\n",
       "          '2004': 1,\n",
       "          'also': 1}),\n",
       " Counter({'python': 1,\n",
       "          'greek': 1,\n",
       "          'word': 1,\n",
       "          'πύθωνπύθωνας': 1,\n",
       "          'genu': 2,\n",
       "          'nonvenom': 1,\n",
       "          'pythons2': 1,\n",
       "          'found': 1,\n",
       "          'africa': 1,\n",
       "          'asia': 1,\n",
       "          'current': 1,\n",
       "          '7': 1,\n",
       "          'speci': 1,\n",
       "          'recognised2': 1,\n",
       "          'member': 1,\n",
       "          'p': 1,\n",
       "          'reticulatu': 1,\n",
       "          'among': 1,\n",
       "          'longest': 1,\n",
       "          'snake': 1,\n",
       "          'known': 1}),\n",
       " Counter({'colt': 3,\n",
       "          'python': 3,\n",
       "          '357': 1,\n",
       "          'magnum': 2,\n",
       "          'calib': 1,\n",
       "          'revolv': 3,\n",
       "          'formerli': 1,\n",
       "          'manufactur': 2,\n",
       "          'compani': 1,\n",
       "          'hartford': 1,\n",
       "          'connecticut': 1,\n",
       "          'sometim': 1,\n",
       "          'refer': 1,\n",
       "          'combat': 1,\n",
       "          'magnum1': 1,\n",
       "          'first': 1,\n",
       "          'introduc': 1,\n",
       "          '1955': 1,\n",
       "          'year': 1,\n",
       "          'smith': 1,\n",
       "          'wesson': 1,\n",
       "          'm29': 1,\n",
       "          '44': 1,\n",
       "          'discontinu': 1,\n",
       "          'target': 1,\n",
       "          'premium': 1,\n",
       "          'market': 1,\n",
       "          'segment': 1,\n",
       "          'firearm': 1,\n",
       "          'collector': 1,\n",
       "          'writer': 1,\n",
       "          'jeff': 1,\n",
       "          'cooper': 1,\n",
       "          'ian': 1,\n",
       "          'v': 1,\n",
       "          'hogg': 1,\n",
       "          'chuck': 1,\n",
       "          'hawk': 1,\n",
       "          'leroy': 1,\n",
       "          'thompson': 1,\n",
       "          'rene': 1,\n",
       "          'smeet': 1,\n",
       "          'martin': 1,\n",
       "          'dougherti': 1,\n",
       "          'describ': 1,\n",
       "          'finest': 1,\n",
       "          'product': 1,\n",
       "          'ever': 1,\n",
       "          'made': 1})]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts = [text1, text2, text3]  #將三組資料合併\n",
    "countlist = []\n",
    "for text in texts:\n",
    "    countlist.append(count_term(text))\n",
    "countlist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tf(word, count):   #tf-idf運算套件\n",
    "    return count[word] / sum(count.values())\n",
    "def n_containing(word, count_list):\n",
    "    return sum(1 for count in count_list if word in count)\n",
    "def idf(word, count_list):\n",
    "    return math.log(len(count_list) / (1 + n_containing(word, count_list)))\n",
    "def tfidf(word, count, count_list):\n",
    "    return tf(word, count) * idf(word, count_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "collections.Counter"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(count_term(text1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.06976744186046512, 0.05813953488372093, 0.023255813953488372, 0.023255813953488372, 0.023255813953488372, 0.011627906976744186, 0.011627906976744186, 0.011627906976744186, 0.011627906976744186, 0.011627906976744186, 0.011627906976744186, 0.011627906976744186, 0.011627906976744186, 0.011627906976744186, 0.011627906976744186, 0.011627906976744186, 0.011627906976744186, 0.011627906976744186, 0.011627906976744186, 0.011627906976744186, 0.011627906976744186, 0.011627906976744186, 0.011627906976744186, 0.011627906976744186, 0.011627906976744186, 0.011627906976744186, 0.011627906976744186, 0.011627906976744186, 0.011627906976744186, 0.011627906976744186, 0.011627906976744186, 0.011627906976744186, 0.011627906976744186, 0.011627906976744186, 0.011627906976744186, 0.011627906976744186, 0.011627906976744186, 0.011627906976744186, 0.011627906976744186, 0.011627906976744186, 0.011627906976744186, 0.011627906976744186, 0.011627906976744186, 0.011627906976744186, 0.011627906976744186, 0.011627906976744186, 0.011627906976744186, 0.011627906976744186, 0.011627906976744186, 0.011627906976744186, 0.011627906976744186, 0.011627906976744186, 0.011627906976744186, 0.011627906976744186, 0.011627906976744186, 0.011627906976744186, 0.011627906976744186, 0.011627906976744186, 0.011627906976744186, 0.011627906976744186, 0.011627906976744186, 0.011627906976744186, 0.011627906976744186, 0.011627906976744186, 0.011627906976744186, 0.011627906976744186, 0.011627906976744186, 0.011627906976744186, 0.011627906976744186, 0.011627906976744186, 0.011627906976744186, 0.011627906976744186, 0.011627906976744186, 0.011627906976744186]\n"
     ]
    }
   ],
   "source": [
    "count_tf=[]    # 先拿text1來做tf的演算\n",
    "for i in count_term(text1):\n",
    "    count_tf.append(tf(i,count_term(text1)))\n",
    "count_tf.sort(reverse=True)\n",
    "print(count_tf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.05813953488372093"
      ]
     },
     "execution_count": 276,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf(\"python\",count2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 264,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_containing(\"python\",countlist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.4054651081081644, 0.4054651081081644, 0.4054651081081644, 0.4054651081081644, 0.4054651081081644, 0.4054651081081644, 0.4054651081081644, 0.4054651081081644, 0.4054651081081644, 0.4054651081081644, 0.4054651081081644, 0.4054651081081644, 0.4054651081081644, 0.4054651081081644, 0.4054651081081644, 0.4054651081081644, 0.4054651081081644, 0.4054651081081644, 0.4054651081081644, 0.4054651081081644, 0.4054651081081644, 0.4054651081081644, 0.4054651081081644, 0.4054651081081644, 0.4054651081081644, 0.4054651081081644, 0.4054651081081644, 0.4054651081081644, 0.4054651081081644, 0.4054651081081644, 0.4054651081081644, 0.4054651081081644, 0.4054651081081644, 0.4054651081081644, 0.4054651081081644, 0.4054651081081644, 0.4054651081081644, 0.4054651081081644, 0.4054651081081644, 0.4054651081081644, 0.4054651081081644, 0.4054651081081644, 0.4054651081081644, 0.4054651081081644, 0.4054651081081644, 0.4054651081081644, 0.4054651081081644, 0.4054651081081644, 0.4054651081081644, 0.4054651081081644, 0.4054651081081644, 0.4054651081081644, 0.4054651081081644, 0.4054651081081644, 0.4054651081081644, 0.4054651081081644, 0.4054651081081644, 0.4054651081081644, 0.4054651081081644, 0.4054651081081644, 0.4054651081081644, 0.4054651081081644, 0.4054651081081644, 0.4054651081081644, 0.4054651081081644, 0.4054651081081644, 0.4054651081081644, 0.4054651081081644, 0.4054651081081644, 0.4054651081081644, 0.4054651081081644, 0.0, 0.0, -0.2876820724517809]\n"
     ]
    }
   ],
   "source": [
    "count_idf=[]    # 先拿text1來做idf的演算\n",
    "for word in count2:\n",
    "    count_idf.append(idf(word,countlist))\n",
    "count_idf.sort(reverse=True)\n",
    "print(count_idf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.2876820724517809"
      ]
     },
     "execution_count": 266,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idf(\"python\",countlist) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.016725701886731448"
      ]
     },
     "execution_count": 267,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idf(\"python\",countlist)*tf(\"python\",count2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top words in document 1\n",
      "\tWord: film, TF-IDF: 0.02829\n",
      "\tWord: madefortv, TF-IDF: 0.00943\n",
      "\tWord: includ, TF-IDF: 0.00943\n",
      "\tWord: california, TF-IDF: 0.00943\n",
      "\tWord: 2000, TF-IDF: 0.00471\n",
      "Top words in document 2\n",
      "\tWord: genu, TF-IDF: 0.03686\n",
      "\tWord: greek, TF-IDF: 0.01843\n",
      "\tWord: word, TF-IDF: 0.01843\n",
      "\tWord: πύθωνπύθωνας, TF-IDF: 0.01843\n",
      "\tWord: nonvenom, TF-IDF: 0.01843\n",
      "Top words in document 3\n",
      "\tWord: colt, TF-IDF: 0.02134\n",
      "\tWord: revolv, TF-IDF: 0.02134\n",
      "\tWord: magnum, TF-IDF: 0.01423\n",
      "\tWord: manufactur, TF-IDF: 0.01423\n",
      "\tWord: 357, TF-IDF: 0.00711\n"
     ]
    }
   ],
   "source": [
    "def main():          \n",
    "    texts = [text1, text2, text3]\n",
    "    countlist = []\n",
    "    for text in texts:\n",
    "        countlist.append(count_term(text))\n",
    "    for i, count in enumerate(countlist):\n",
    "        print(\"Top words in document {}\".format(i + 1))\n",
    "        scores = {word: tfidf(word, count, countlist) for word in count}\n",
    "        sorted_words = sorted(scores.items(), key = lambda x: x[1], reverse=True)\n",
    "        for word, score in sorted_words[:5]:\n",
    "            print(\"\\tWord: {}, TF-IDF: {}\".format(word, round(score, 5)))\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
